{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4HI2mpwlrcn"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2023-10-27T06:01:14.712586Z",
     "iopub.status.busy": "2023-10-27T06:01:14.711974Z",
     "iopub.status.idle": "2023-10-27T06:01:14.715753Z",
     "shell.execute_reply": "2023-10-27T06:01:14.715164Z"
    },
    "id": "679Lmwt3l1Bk"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSPCom-KmApV"
   },
   "source": [
    "# Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klAltGp8ycek"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/images/cnn\">\n",
    "    <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />\n",
    "    View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/cnn.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
    "    Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/cnn.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
    "    View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/images/cnn.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLGkt5qiyz4E"
   },
   "source": [
    "This tutorial demonstrates training a simple [Convolutional Neural Network](https://developers.google.com/machine-learning/glossary/#convolutional_neural_network) (CNN) to classify [CIFAR images](https://www.cs.toronto.edu/~kriz/cifar.html). Because this tutorial uses the [Keras Sequential API](https://www.tensorflow.org/guide/keras/overview), creating and training your model will take just a few lines of code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7KBpffWzlxH"
   },
   "source": [
    "### Import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T06:01:14.719225Z",
     "iopub.status.busy": "2023-10-27T06:01:14.719007Z",
     "iopub.status.idle": "2023-10-27T06:01:17.352307Z",
     "shell.execute_reply": "2023-10-27T06:01:17.351456Z"
    },
    "id": "iAve6DCL4JH4"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy.io\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRFxccghyMVo"
   },
   "source": [
    "### Download and prepare the CIFAR10 dataset\n",
    "\n",
    "\n",
    "The CIFAR10 dataset contains 60,000 color images in 10 classes, with 6,000 images in each class. The dataset is divided into 50,000 training images and 10,000 testing images. The classes are mutually exclusive and there is no overlap between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T06:01:17.356811Z",
     "iopub.status.busy": "2023-10-27T06:01:17.356346Z",
     "iopub.status.idle": "2023-10-27T06:01:23.459377Z",
     "shell.execute_reply": "2023-10-27T06:01:23.458566Z"
    },
    "id": "JWoEqyMuXFF4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(8671, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "print(train_images.shape)\n",
    "\n",
    "mat = scipy.io.loadmat('../../caltech101_silhouettes_28.mat')\n",
    "inputs = mat.get('X')\n",
    "s = inputs.shape\n",
    "images = np.array([np.reshape(inputs[i,:],[28,28]) for i in range(s[0])])\n",
    "images = tf.reshape(images,shape=[8671,28,28,1])\n",
    "images = np.array(images)\n",
    "labels = np.array(mat.get('Y')).T -1\n",
    "print(images.shape)\n",
    "\n",
    "train_images,test_images,train_labels,test_labels = train_test_split(images, labels, train_size=0.9, test_size=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wArwCTJJlUa"
   },
   "source": [
    "### Verify the data\n",
    "\n",
    "To verify that the dataset looks correct, let's plot the first 25 images from the training set and display the class name below each image:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oewp-wYg31t9"
   },
   "source": [
    "### Create the convolutional base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3hQvqXpNyN3x"
   },
   "source": [
    "The 6 lines of code below define the convolutional base using a common pattern: a stack of [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) and [MaxPooling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D) layers.\n",
    "\n",
    "As input, a CNN takes tensors of shape (image_height, image_width, color_channels), ignoring the batch size. If you are new to these dimensions, color_channels refers to (R,G,B). In this example, you will configure your CNN to process inputs of shape (32, 32, 3), which is the format of CIFAR images. You can do this by passing the argument `input_shape` to your first layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T06:01:24.118814Z",
     "iopub.status.busy": "2023-10-27T06:01:24.118571Z",
     "iopub.status.idle": "2023-10-27T06:01:26.532957Z",
     "shell.execute_reply": "2023-10-27T06:01:26.532276Z"
    },
    "id": "L9YmGQBQPrdn"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu', input_shape=(28, 28,1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(101, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvDVFkg-2DPm"
   },
   "source": [
    "Let's display the architecture of your model so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T06:01:26.536992Z",
     "iopub.status.busy": "2023-10-27T06:01:26.536751Z",
     "iopub.status.idle": "2023-10-27T06:01:26.550266Z",
     "shell.execute_reply": "2023-10-27T06:01:26.549695Z"
    },
    "id": "8-C4XBg4UTJy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 26, 26, 128)       1280      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 13, 13, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 21632)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 101)               2184933   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2186213 (8.34 MB)\n",
      "Trainable params: 2186213 (8.34 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_j-AXYeZ2GO5"
   },
   "source": [
    "Above, you can see that the output of every Conv2D and MaxPooling2D layer is a 3D tensor of shape (height, width, channels). The width and height dimensions tend to shrink as you go deeper in the network. The number of output channels for each Conv2D layer is controlled by the first argument (e.g., 32 or 64). Typically,  as the width and height shrink, you can afford (computationally) to add more output channels in each Conv2D layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_v8sVOtG37bT"
   },
   "source": [
    "### Add Dense layers on top\n",
    "\n",
    "To complete the model, you will feed the last output tensor from the convolutional base (of shape (4, 4, 64)) into one or more Dense layers to perform classification. Dense layers take vectors as input (which are 1D), while the current output is a 3D tensor. First, you will flatten (or unroll) the 3D output to 1D,  then add one or more Dense layers on top. CIFAR has 10 output classes, so you use a final Dense layer with 10 outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipGiQMcR4Gtq"
   },
   "source": [
    "Here's the complete architecture of your model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNKXi-Gy3RO-"
   },
   "source": [
    "The network summary shows that (4, 4, 64) outputs were flattened into vectors of shape (1024) before going through two Dense layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3odqfHP4M67"
   },
   "source": [
    "### Compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T06:01:26.619840Z",
     "iopub.status.busy": "2023-10-27T06:01:26.619256Z",
     "iopub.status.idle": "2023-10-27T06:02:36.728327Z",
     "shell.execute_reply": "2023-10-27T06:02:36.727472Z"
    },
    "id": "MdDzI75PUXrG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217/217 [==============================] - 2s 10ms/step - loss: 3.4084 - accuracy: 0.2764 - val_loss: 4.6311 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "217/217 [==============================] - 2s 10ms/step - loss: 3.3993 - accuracy: 0.2764 - val_loss: 4.6237 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "217/217 [==============================] - 2s 10ms/step - loss: 3.3967 - accuracy: 0.2764 - val_loss: 4.6266 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "217/217 [==============================] - 2s 9ms/step - loss: 3.3945 - accuracy: 0.2765 - val_loss: 4.6251 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "217/217 [==============================] - 2s 10ms/step - loss: 3.3887 - accuracy: 0.2780 - val_loss: 4.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "217/217 [==============================] - 2s 10ms/step - loss: 3.3811 - accuracy: 0.2797 - val_loss: 4.6222 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "217/217 [==============================] - 2s 9ms/step - loss: 3.3717 - accuracy: 0.2804 - val_loss: 4.6280 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "217/217 [==============================] - 2s 9ms/step - loss: 3.3715 - accuracy: 0.2804 - val_loss: 4.6215 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "217/217 [==============================] - 2s 10ms/step - loss: 3.3680 - accuracy: 0.2804 - val_loss: 4.6220 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "217/217 [==============================] - 2s 9ms/step - loss: 3.3683 - accuracy: 0.2804 - val_loss: 4.6216 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=10, validation_split=0.1111111111111)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKgyC5K_4O0d"
   },
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T06:02:36.732053Z",
     "iopub.status.busy": "2023-10-27T06:02:36.731781Z",
     "iopub.status.idle": "2023-10-27T06:02:38.004957Z",
     "shell.execute_reply": "2023-10-27T06:02:38.004232Z"
    },
    "id": "gtyDF0MKUcM7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2763840854167938, 0.2763840854167938, 0.2763840854167938, 0.2765282690525055, 0.27797001600265503, 0.2797001302242279, 0.2804209887981415, 0.2804209887981415, 0.2804209887981415, 0.2804209887981415] [0 1 2 3 4 5 6 7 8 9]\n",
      "(8671, 28, 28, 1)\n",
      "(8671, 1)\n",
      "(868, 28, 28, 1)\n",
      "(868, 1)\n",
      "28/28 - 0s - loss: 3.4365 - accuracy: 0.2776 - 84ms/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print(history.history['accuracy'],np.arange(0,len(history.history['accuracy'])))\n",
    "plt.plot(np.arange(0,len(history.history['accuracy'])),history.history['accuracy'], label='accuracy')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-27T06:02:38.008341Z",
     "iopub.status.busy": "2023-10-27T06:02:38.008035Z",
     "iopub.status.idle": "2023-10-27T06:02:38.011981Z",
     "shell.execute_reply": "2023-10-27T06:02:38.011358Z"
    },
    "id": "0LvwaKhtUdOo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27764976024627686\n"
     ]
    }
   ],
   "source": [
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cfJ8AR03gT5"
   },
   "source": [
    "Your simple CNN has achieved a test accuracy of over 70%. Not bad for a few lines of code! For another CNN style, check out the [TensorFlow 2 quickstart for experts](https://www.tensorflow.org/tutorials/quickstart/advanced) example that uses the Keras subclassing API and `tf.GradientTape`."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cnn.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
